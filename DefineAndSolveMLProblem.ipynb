{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Define and Solve an ML Problem of Your Choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Build the DataFrame\n",
    "\n",
    "For my project I will be using `censusData.csv`, a file with data from the \"census\" data set that contains Census information from 1994.\n",
    "\n",
    "I imported the .csv file into a pandas DataFrame by locating it in a directory and converting it into a DataFrame to be used for data manipuation before I create my machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex_selfID</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Female</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Non-Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age         workclass  fnlwgt  education  education-num  \\\n",
       "0  39.0         State-gov   77516  Bachelors             13   \n",
       "1  50.0  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2  38.0           Private  215646    HS-grad              9   \n",
       "3  53.0           Private  234721       11th              7   \n",
       "4  28.0           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race  sex_selfID  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White  Non-Female   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White  Non-Female   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White  Non-Female   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black  Non-Female   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black      Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income_binary  \n",
       "0          2174             0            40.0  United-States         <=50K  \n",
       "1             0             0            13.0  United-States         <=50K  \n",
       "2             0             0            40.0  United-States         <=50K  \n",
       "3             0             0            40.0  United-States         <=50K  \n",
       "4             0             0            40.0           Cuba         <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adultDataSet_filename = os.path.join(os.getcwd(), \"data\", \"censusData.csv\")\n",
    "df = pd.read_csv(adultDataSet_filename)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Define the ML Problem\n",
    "\n",
    "Using the Census dataset, I will be comparing an individual's income to $50,000 (the label is the `income_binary` column). Given the label is a binary representation of whether the individual's income is less than or equal to the target income or greater than it, the model I will create will solve a supervised learning problem, more specifically a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        <=50K\n",
       "1        <=50K\n",
       "2        <=50K\n",
       "3        <=50K\n",
       "4        <=50K\n",
       "         ...  \n",
       "32556    <=50K\n",
       "32557     >50K\n",
       "32558    <=50K\n",
       "32559    <=50K\n",
       "32560     >50K\n",
       "Name: income_binary, Length: 32561, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['income_binary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features I will initially use are:\n",
    "- `age` (as a higher age corresponds with more work experience and an increase in an individual's income)\n",
    "- `education-num` (the revised education column that sequences education levels from lowest to highest)\n",
    "- `occupation` (some occupations pay better than others - I will convert this column into numerical data similar to the education_num column)\n",
    "- `race` and `sex_selfID` (to understand trends with racial and sexual bias in the workplace in correlation with an individual's income)\n",
    "- `hours-per-week` (part-time employees make less than full-time employees as they do not work as consistently as their full-time counterparts)\n",
    "- `native-country` (migrant workers in the United States have historically taken lower-income jobs and do not earn as much as citizens by birth)\n",
    "\n",
    "I plan on using Scikit-learn's `SelectKBest` function after I train my model for the first time to confirm which features are actually correspond the most to the examples' labels. I will use a LogisticRegression model to fit data points that are closer to 0 on the graph with the <=50k label and those whose are closer to 1 with the >50k label.\n",
    "\n",
    "I want to initially focus on two features, which I briefly explained above: race and sex_selfID. There exists a wage gap between male and female employees, as is there between white employees and employees of color. Per <b>[Pew Research Labs](https://www.pewresearch.org/short-reads/2016/07/01/racial-gender-wage-gaps-persist-in-u-s-despite-some-progress/)'</b> 2015 findings, more than two decades after the creation of the Census dataset, Black and Hispanic men made about 70% of a white man's salary, while women of all ethinicities made less than their male coworkers. I want to determine if an individual's demographics, not just their education level, occupation, or hours worked, affects their yearly income. I plan on creating two sets of `X` data: one with all the above features and one without the `race` and `sex_selfID` features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understand Your Data\n",
    "\n",
    "Now that we have defined our machine learning problem and have identified our features and label, we need to inspect the dataset. We've looked at the first few examples of our dataset, so we can now start analyzing the shape of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have determined our dataset has 32,561 examples. One of the most important steps in data preprocessing is determining if any columns have missing values and how to address them to make a clean dataset our model can be trained on. I will be using the `df.describe()` method to first analyze the numerical values and determine how to clean the dataset using various statistical metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32399.000000</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32236.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.589216</td>\n",
       "      <td>1.897784e+05</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>615.907773</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>40.450428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.647862</td>\n",
       "      <td>1.055500e+05</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>2420.191974</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.353748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.178270e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.783560e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.370510e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>14084.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "count  32399.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \n",
       "mean      38.589216  1.897784e+05      10.080679    615.907773     87.303830   \n",
       "std       13.647862  1.055500e+05       2.572720   2420.191974    402.960219   \n",
       "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06      16.000000  14084.000000   4356.000000   \n",
       "\n",
       "       hours-per-week  \n",
       "count    32236.000000  \n",
       "mean        40.450428  \n",
       "std         12.353748  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the statistical breakdown of the numeric columns in the Census dataset, in which three of my initial features appear. Before any data manipulation is performed on the DataFrame, we need to make sense of the numerical data my model will be based around:\n",
    "\n",
    "#### Understanding the `age` feature\n",
    "The `age` feature is self-explanatory: give the age of a given individual at the time of the census. The mean age is between 38 and 39, an average age for a mid-career individual. The lowest age is 17 years and the highest age is 90, but I would like to remove any outliers in my data set. I will use SciPy's `winsorize` function to address outliers and diminish the `age` column's standard deviation.\n",
    "\n",
    "Also notice that most columns have a <b>count</b> value of 32,561, the number of examples in the census dataset. The `age` column has a lower number, so it contains missing values. I will create a new column and drop the original `age` column so that my dataset favors the winsorized values, then I'll fill in any missing values with the mean of the winsorized data.\n",
    "\n",
    "#### Understanding the `education-num` feature\n",
    "This column takes the original `education` column in the data set and enumerates its contents in chronological order, corresponding with a given individual's highest education level. For example, a 1 represents the individual's highest education level falls between first grade and fourth grade while a 16 represents their highest education level is a doctorate degree. The average individual in the dataset has completed some college, as represented by a mean value just greater than 10, while half of the dataset includes individuals with education levels ranging from a high school diploma (9) to an associate degree (12).\n",
    "\n",
    "This column does not have any missing values to worry about.\n",
    "\n",
    "#### Understanding the `hours-per-week` feature\n",
    "The average individual in the dataset works about 40 hours a week, as shown by the mean of the `hours-per-week` column as well as the difference of 5 hours between the first and third quartiles of the dataset. To address any missing values in this column, I will replace with the <b>mean</b> value, as it is close enough to the `hours-per-week` value for the interquartile range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Define the Project Plan\n",
    "\n",
    "I plan on initially using a `LogisticRegression` model, using all default arguments except for a `max_iters` value of 1000, for a basic binary classification: predict if an unlabeled individual will have an income of either less than or equal to 50,000 or greater than 50,000. Using two different sets of features for `X`: one that includes all the features outlined in Part 2, and one that uses the same features but omits `race` and `sex_selfID`, to understand trends in wage gap upon minority workers. I would like to return the probability predictions as well as the accuracy scores of the model on my two `X` datasets.\n",
    "\n",
    "From here, I will create a parameter grid with various regularization values for `C`, as well as various values for `max_iters`. I will then perform a grid search on another `LogisticRegression` model with no arguments given and the parameter grid to find the best values for `C` and `max_iters` on both datasets; from here I will create another `LogisticRegression` model using the best parameters and train that on both `X` datasets.\n",
    "\n",
    "My goal is to see how important an individual's race and sex is to their income, and I want to see if a model that omits such categories outperforms or underperforms the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Implement the Project Plan\n",
    "\n",
    "As I just mentioned, I will need to import several functions from the Scikit-learn package. More will be imported later in this notebook, such as the `SelectKBest` and `f_classif` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will begin preparing the dataset to be used by a machine learning model by converting the object-typed label as a boolean, so that my model can better analyze the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "32556    1\n",
       "32557    0\n",
       "32558    1\n",
       "32559    1\n",
       "32560    0\n",
       "Name: income_binary, Length: 32561, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['income_binary'] = (df['income_binary'] == '<=50K').astype(int)\n",
    "df['income_binary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our label is properly converted into an easier-to-understand datatype, we can start cleaning the rest of the data. We will begin with determining which columns have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                162\n",
       "workclass         1836\n",
       "fnlwgt               0\n",
       "education            0\n",
       "education-num        0\n",
       "marital-status       0\n",
       "occupation        1843\n",
       "relationship         0\n",
       "race                 0\n",
       "sex_selfID           0\n",
       "capital-gain         0\n",
       "capital-loss         0\n",
       "hours-per-week     325\n",
       "native-country     583\n",
       "income_binary        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the non-numerical features I wanted to include in my training data have many missing values. As I said earlier, I will remove examples where the `age` feature is null and replace any missing values in the `hours-per-week` column with the mean of the column. I will replace any null value in `native-country` with the phrase \"unavailable,\" but there are so many more missing values in the `occupation` column than the other columns I planned on using with missing values, so I will just omit it in my cleansed data. Also, another column (the `workclass` column) may come in handy later but I do not plan on initially using it, but I will still drop it because of how many missing values there are.\n",
    "\n",
    "Before we edit any missing columns, we will use SciPy's `winsorize` function to replace outliers in the `age` column. We will create a new column of the DataFrame with the replaced values for `age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "df['age-wins'] = stats.mstats.winsorize(df['age'], limits = [0.01, 0.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check that the columns `age` and `age-wins` are not identical by finding the unique differences between values in the two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., nan,  1., 12.,  2.,  3., 10.,  4.,  5.,  6.,  7.,  8.,  9.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['age'] - df['age-wins']).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how there is an `NaN` element in the array of unique differences. We haven't replaced any missing values yet, but now that the outliers in the `age` column have been replaced with values that are closer to the rest of the data, we can start manipulating null elements.\n",
    "\n",
    "We will now remove the `workclass`, `occupation`, and `age` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['workclass', 'occupation', 'age'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also drop some columns that contain object values that may not contribute to the machine learning model's predictions. The `fnlwgt`, `education`, `marital-status`, and `relationship` columns will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['fnlwgt', 'education', 'marital-status', 'relationship'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now replace missing values in the `age-wins`, `hours-per-week`, and `native-country` with their predetermined values. By using NumPy's `mean` function, we will find the average value in our two numerical columns and replace any null example with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age-wins'].fillna(np.mean(df['age-wins']), inplace = True)\n",
    "df['hours-per-week'].fillna(np.mean(df['hours-per-week']), inplace = True)\n",
    "df['native-country'].fillna('unavailable', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we will enumerate the `sex_selfID`, `race`, and `native-country` columns. For `sex_selfID`, I will take an approach similar to converting our label into a boolean column. For the other two, I will perform one-hot encoding, create a separate DataFrame for each one-hot encoding, and concatenate the DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex_selfID'] = (df['sex_selfID'] == 'Female').astype(int)\n",
    "\n",
    "df_race = pd.get_dummies(df['race'], prefix = 'race_')\n",
    "df_native_country = pd.get_dummies(df['native-country'], prefix = 'native_country_')\n",
    "\n",
    "df = df.join([df_race, df_native_country])\n",
    "df.drop(columns = ['race', 'native-country'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all the changes to our data, let's observe the first few examples of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education-num</th>\n",
       "      <th>sex_selfID</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income_binary</th>\n",
       "      <th>age-wins</th>\n",
       "      <th>race__Amer-Indian-Inuit</th>\n",
       "      <th>race__Asian-Pac-Islander</th>\n",
       "      <th>race__Black</th>\n",
       "      <th>...</th>\n",
       "      <th>native_country__Puerto-Rico</th>\n",
       "      <th>native_country__Scotland</th>\n",
       "      <th>native_country__South</th>\n",
       "      <th>native_country__Taiwan</th>\n",
       "      <th>native_country__Thailand</th>\n",
       "      <th>native_country__Trinadad&amp;Tobago</th>\n",
       "      <th>native_country__United-States</th>\n",
       "      <th>native_country__Vietnam</th>\n",
       "      <th>native_country__Yugoslavia</th>\n",
       "      <th>native_country__unavailable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14084</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5178</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   education-num  sex_selfID  capital-gain  capital-loss  hours-per-week  \\\n",
       "0             13           0          2174             0            40.0   \n",
       "1             13           0             0             0            13.0   \n",
       "2              9           0             0             0            40.0   \n",
       "3              7           0             0             0            40.0   \n",
       "4             13           1             0             0            40.0   \n",
       "5             14           1             0             0            40.0   \n",
       "6              5           1             0             0            16.0   \n",
       "7              9           0             0             0            45.0   \n",
       "8             14           1         14084             0            50.0   \n",
       "9             13           0          5178             0            40.0   \n",
       "\n",
       "   income_binary  age-wins  race__Amer-Indian-Inuit  race__Asian-Pac-Islander  \\\n",
       "0              1      39.0                        0                         0   \n",
       "1              1      50.0                        0                         0   \n",
       "2              1      38.0                        0                         0   \n",
       "3              1      53.0                        0                         0   \n",
       "4              1      28.0                        0                         0   \n",
       "5              1      37.0                        0                         0   \n",
       "6              1      49.0                        0                         0   \n",
       "7              0      52.0                        0                         0   \n",
       "8              0      31.0                        0                         0   \n",
       "9              0      42.0                        0                         0   \n",
       "\n",
       "   race__Black  ...  native_country__Puerto-Rico  native_country__Scotland  \\\n",
       "0            0  ...                            0                         0   \n",
       "1            0  ...                            0                         0   \n",
       "2            0  ...                            0                         0   \n",
       "3            1  ...                            0                         0   \n",
       "4            1  ...                            0                         0   \n",
       "5            0  ...                            0                         0   \n",
       "6            1  ...                            0                         0   \n",
       "7            0  ...                            0                         0   \n",
       "8            0  ...                            0                         0   \n",
       "9            0  ...                            0                         0   \n",
       "\n",
       "   native_country__South  native_country__Taiwan  native_country__Thailand  \\\n",
       "0                      0                       0                         0   \n",
       "1                      0                       0                         0   \n",
       "2                      0                       0                         0   \n",
       "3                      0                       0                         0   \n",
       "4                      0                       0                         0   \n",
       "5                      0                       0                         0   \n",
       "6                      0                       0                         0   \n",
       "7                      0                       0                         0   \n",
       "8                      0                       0                         0   \n",
       "9                      0                       0                         0   \n",
       "\n",
       "   native_country__Trinadad&Tobago  native_country__United-States  \\\n",
       "0                                0                              1   \n",
       "1                                0                              1   \n",
       "2                                0                              1   \n",
       "3                                0                              1   \n",
       "4                                0                              0   \n",
       "5                                0                              1   \n",
       "6                                0                              0   \n",
       "7                                0                              1   \n",
       "8                                0                              1   \n",
       "9                                0                              1   \n",
       "\n",
       "   native_country__Vietnam  native_country__Yugoslavia  \\\n",
       "0                        0                           0   \n",
       "1                        0                           0   \n",
       "2                        0                           0   \n",
       "3                        0                           0   \n",
       "4                        0                           0   \n",
       "5                        0                           0   \n",
       "6                        0                           0   \n",
       "7                        0                           0   \n",
       "8                        0                           0   \n",
       "9                        0                           0   \n",
       "\n",
       "   native_country__unavailable  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  \n",
       "5                            0  \n",
       "6                            0  \n",
       "7                            0  \n",
       "8                            0  \n",
       "9                            0  \n",
       "\n",
       "[10 rows x 54 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our DataFrame has been manipulated to be better understood by a machine learning model.\n",
    "\n",
    "We will now define our `X` and `y` parameters for our model. Remember that we will be using two separate sets of `X`: one that includes the `race` and `sex_selfID` features and one that does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['income_binary']\n",
    "X_1 = df.drop(columns = 'income_binary', axis = 1)\n",
    "\n",
    "cols_to_omit = [col for col in list(df.columns) if 'race_' in col]\n",
    "cols_to_omit.append('income_binary')\n",
    "cols_to_omit.append('sex_selfID')\n",
    "X_2 = df.drop(columns = cols_to_omit, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset has been manipulated to create two sets of features `X` and a label `y`. We will now use Scikit-learn's `train_test_split` function to divide our data into training data and test data. Our test data will be 20% the size of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_1, y, test_size = 0.10, random_state = 123)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_2, y, test_size = 0.10, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the DataFrame `X_1` contains all the features in the original dataset while `X_2` is identical but omits any columns associated with an individual's race and sex.\n",
    "\n",
    "We will now create our default `LogisticRegression` models, which will be scaled to perform on larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for default model on dataset 1: 0.8265274792754068\n",
      "Accuracy score for default model on dataset 2: 0.8203868590727663\n"
     ]
    }
   ],
   "source": [
    "model_default1 = LogisticRegression()\n",
    "scaler1 = StandardScaler()\n",
    "pipeline_default1 = make_pipeline(scaler1, model_default1)\n",
    "pipeline_default1.fit(X_train1, y_train1)\n",
    "\n",
    "preds_default1 = pipeline_default1.predict(X_test1)\n",
    "acc_default1 = accuracy_score(y_test1, preds_default1)\n",
    "print('Accuracy score for default model on dataset 1:', acc_default1)\n",
    "\n",
    "model_default2 = LogisticRegression()\n",
    "scaler2 = StandardScaler()\n",
    "pipeline_default2 = make_pipeline(scaler2, model_default2)\n",
    "pipeline_default2.fit(X_train2, y_train2)\n",
    "\n",
    "preds_default2 = pipeline_default2.predict(X_test2)\n",
    "acc_default2 = accuracy_score(y_test2, preds_default2)\n",
    "print('Accuracy score for default model on dataset 2:', acc_default2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we create a default `LogisticRegression` model, we get an 82.7% accuracy rate on dataset 1 and an 82% accuracy rate on dataset 2. Already we can see that a full dataset yields slightly more accurate results than one with key features missing, and we notice there is already signs of a wage gap bias among women and employees of color.\n",
    "\n",
    "We will now create our second set of models, with a maximum number of iterations to 100,000. However, we will create a parameter grid containing various values for `max_iter` and regularization `C`, to be used in a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'logisticregression__max_iter': [100, 200, 500, 1000, 5000, 10000],\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'logisticregression__solver': ['lbfgs', 'liblinear']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Scikit-learn's `GridSearchCV` to begin a grid search using a new default model, the parameter grid we just declared, and a cross-validation value of 5. This may take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search on dataset 1\n",
      "Done with dataset 1\n",
      "Running grid search on dataset 2\n",
      "Done with dataset 2\n"
     ]
    }
   ],
   "source": [
    "print('Running grid search on dataset 1')\n",
    "\n",
    "model_grid1 = LogisticRegression()\n",
    "scaler_grid1 = StandardScaler()\n",
    "pipeline_grid1 = make_pipeline(scaler_grid1, model_grid1)\n",
    "\n",
    "grid1 = GridSearchCV(pipeline_grid1, param_grid, cv = 5)\n",
    "grid_search1 = grid1.fit(X_train1, y_train1)\n",
    "\n",
    "print('Done with dataset 1')\n",
    "\n",
    "print('Running grid search on dataset 2')\n",
    "\n",
    "model_grid2 = LogisticRegression()\n",
    "scaler_grid2 = StandardScaler()\n",
    "pipeline_grid2 = make_pipeline(scaler_grid2, model_grid2)\n",
    "\n",
    "grid2 = GridSearchCV(pipeline_grid2, param_grid, cv = 5)\n",
    "grid_search2 = grid2.fit(X_train2, y_train2)\n",
    "\n",
    "print('Done with dataset 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will print the results of each grid search, beginning with dataset 1, the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 1,\n",
       " 'logisticregression__max_iter': 100,\n",
       " 'logisticregression__solver': 'liblinear'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search1.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the most optimal model fo dataset 1 happens to be the default model. (Note that a default `LogisticRegression` model has a `C` regularization value of 1.0 and a `max_iter` value of 100.) We will now print the best parameters of dataset 2, the dataset with race and sex categories omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 0.01,\n",
       " 'logisticregression__max_iter': 100,\n",
       " 'logisticregression__solver': 'liblinear'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what parameters allow the model to optimize its performance, we can create our two best models, even though the best model for dataset 1 happens to be the default model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for best model on dataset 1: 0.8265274792754068\n",
      "Accuracy score for best model on dataset 2: 0.8216149831132944\n"
     ]
    }
   ],
   "source": [
    "model_best1 = LogisticRegression(max_iter = best_maxiter1, C = best_C1)\n",
    "scaler_best1 = StandardScaler()\n",
    "pipeline_best1 = make_pipeline(scaler_best1, model_best1)\n",
    "pipeline_best1.fit(X_train1, y_train1)\n",
    "\n",
    "preds_best1 = pipeline_best1.predict(X_test1)\n",
    "acc_best1 = accuracy_score(y_test1, preds_best1)\n",
    "print('Accuracy score for best model on dataset 1:', acc_best1)\n",
    "\n",
    "model_best2 = LogisticRegression(max_iter = best_maxiter2, C = best_C2)\n",
    "scaler_best2 = StandardScaler()\n",
    "pipeline_best2 = make_pipeline(scaler_best2, model_best2)\n",
    "pipeline_best2.fit(X_train2, y_train2)\n",
    "\n",
    "preds_best2 = pipeline_best2.predict(X_test2)\n",
    "acc_best2 = accuracy_score(y_test2, preds_best2)\n",
    "print('Accuracy score for best model on dataset 2:', acc_best2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"best\" model (the default model) still performs with an 82.7% accuracy rate. Dataset 2's best model, however, does perform better with an 82.2% accuracy rate. We start to see a smaller gap between accuracy rates on the dataset where all the features are included against the dataset where any mention of the race or sex of an individual is omitted.\n",
    "\n",
    "No matter what model is built to train the data regarding an individual's demographics and their yearly income, whether it be a default model or an optimized model, we can still notice a slight difference in including an individual's race and sex in the data as opposed to not. This shows that a wage gap does exist in the workplace against women and employees of color, as models that include race and sex information do predict better than models which omit such information about an individual. While this dataset is about three decades old, wage gaps still exist due to many workplaces being historically dominated by white men. This model aimed to examine and share how machine learning models are unable to make predictions on an individual's income without knowing about their demographic information (that is, the race and sex they identify with most)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
